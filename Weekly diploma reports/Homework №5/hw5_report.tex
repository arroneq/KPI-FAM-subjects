% !TeX program = lualatex
% !TeX encoding = utf8
% !BIB program = biber
% !TeX spellcheck = uk_UA

\documentclass{mathreport}
\input{packages}

\begin{document}

\ReportPreamble{}
\ReportName{Домашнє завдання №5}
\ReportSubject{}

% \AuthorInfo{Студент 5 курсу, групи КМ-31мн,}
% \AuthorName{Цибульник Антон Владиславович}

% \SupervisorInfo{Доцент кафедри ПМА,}
% \SupervisorName{Андрійчук Олег Валентинович}

% warning: in order to fit the text in the very right side of a page, set the longest label
\TheLongestLabel{Цибульник Антон Владиславович}

\import{Title/}{title}

\tableofcontents

\newpage

\subsection*{Задача 2. MCMC algorithms}
\addcontentsline{toc}{section}{Задача 2. MCMC algorithms}
\setcounter{subsection}{2}
\setcounter{equation}{0}

\subsubsection*{Завдання (a)}
\addcontentsline{toc}{subsection}{Завдання (a)}

Нехай~$\lambda(\theta)$~--- деякий апостеріорний розподіл невідомого параметра~$\theta \in \mathbb{R}$. Алгоритм МСМС має на меті згенерувати такий ланцюг Маркова~$\left\{ \theta^{(t)} \right\}_{t \geqslant 0}$ на множині станів $\mathbb{R}$, для якого~$\lambda(\theta)$ є інваріантним розподілом. Нижче наведено один з варіантів МСМС, а саме~--- алгоритм Метрополіса-Гастінгса:
\begin{enumerate}
    \item Задати початкове значення~$\theta^{(0)} \in \mathbb{R}$ та розподіл пропозицій~$q(y\, |\, x):$
    \begin{equation}
        \forall t \geqslant 1 \text{ та } \forall x,y \in \mathbb{R}: q(y\, |\, x) = P\left( \theta^{(t)} = y\, |\, \theta^{(t-1)} = x \right)
    \end{equation}    
    \item Для $t=1,\ldots,M$ повторювати кроки:
    \begin{enumerate}
        \item Згенерувати кандидата $v \sim q(v\, |\, u)$, де $u = \theta^{(t-1)}$;
        \item Обчислити імовірність прийняття~$\alpha(v\, |\, u)$ кандидата~$v:$
        \begin{equation} 
            \alpha(v\, |\, u) = \min\left\{ 
                1,\, \frac{\lambda(v)\,q(u\, |\, v)}{\lambda(u)\,q(v\, |\, u)} 
            \right\}
        \end{equation}
        \item З імовірністю~$\alpha(v\, |\, u)$ покласти~$\theta^{(t)} = v$, з імовірністю~$1-\alpha(v\, |\, u)$ покласти~$\theta^{(t)} = u$.
    \end{enumerate}
\end{enumerate}

Завдання: показати, що~$\lambda(\theta)$~--- стаціонарний розподіл для ланцюга~$\left\{ \theta^{(t)} \right\}_{t \geqslant 0}$.

\subsubsection*{Розв'язок}

\begin{definition}\label{def: stationary distribution}
    Розподіл~$\pi$ ланцюга Маркова з розподілом перехідних імовірностей~$Q(y\, |\, x)$ називають стаціонарним, якщо
    \begin{equation}
        \forall y \in \mathbb{R}: \pi(y) = \int\limits_{\mathbb{R}} Q(y\, |\, x)\,\pi(x)\,dx
    \end{equation} 
\end{definition}

\begin{theorem}\label{theorem: detailed balance}
    Якщо для деякого розподілу~$\pi$ ланцюга Маркова і деякого розподілу станів~$Q(y\, |\, x)$ виконується рівняння балансу
    \begin{equation}
        \forall x,y \in \mathbb{R}: \pi(x)\,Q(y\, |\, x) = \pi(y)\,Q(x\, |\, y),
    \end{equation} 
    то~$\pi$ є стаціонарним розподілом для~$Q(y\, |\, x)$.

    \begin{proof}
        Якщо $\forall x,y \in \mathbb{R}$ справедливо    
        \begin{equation}
            \pi(x)\,Q(y\, |\, x) = \pi(y)\,Q(x\, |\, y),
        \end{equation} 
        тоді проінтегрувавши обидві частини рівняння, матимемо
        \begin{equation}
           \int\limits_{\mathbb{R}}\pi(x)\,Q(y\, |\, x)\,dx = \int\limits_{\mathbb{R}}\pi(y)\,Q(x\, |\, y)\,dx,
        \end{equation}
        а отже, згідно властивостей розподілу станів отримуємо
        \begin{equation}
            \int\limits_{\mathbb{R}}\pi(x)\,Q(y\, |\, x)\,dx = \int\limits_{\mathbb{R}}\pi(y)\,Q(x\, |\, y)\,dx = \pi(y)
        \end{equation}
        Таким чином, в силу Озн.~\ref{def: stationary distribution} розподіл $\pi$ є стаціонарним.
    \end{proof}
\end{theorem}

Алгоритм МСМС будує ланцюг Маркова з розподілом станів такого вигляду:
\begin{equation}
    \forall x,y \in \mathbb{R}: Q(y\, |\, x) = q(y\, |\, x)\,\alpha(y\, |\, x)
\end{equation}

Відтак, перевіримо справедливість рівняння балансу для апостеріорного розподілу~$\lambda(\theta)$, згенерованого за допомогою МСМС:
\begin{align*}
    \forall x,y \in \mathbb{R}: \lambda(x)\,Q(y\, |\, x) 
        & = \lambda(x)\,q(y\, |\, x)\,\alpha(y\, |\, x) = \\
        & = \lambda(x)\,q(y\, |\, x) \cdot \min\left\{ 
            1,\, \frac{\lambda(y)\,q(x\, |\, y)}{\lambda(x)\,q(y\, |\, x)} 
        \right\} = \\
        & = \min\left\{ 
            \lambda(x)\,q(y\, |\, x),\, \lambda(x)\,q(y\, |\, x)\,\frac{\lambda(y)\,q(x\, |\, y)}{\lambda(x)\, q(y\, |\, x)}
        \right\} = \\
        & = \min\left\{ 
            \lambda(x)\,q(y\, |\, x),\, \lambda(y)\,q(x\, |\, y)
        \right\} = \\
        & = \lambda(y)\,q(x\, |\, y) \cdot \min\left\{ 
            \frac{\lambda(x)\,q(y\, |\, x)}{\lambda(y)\,q(x\, |\, y)},\, 1
        \right\} = \\
        & = \lambda(y)\,q(x\, |\, y)\,\alpha(x\, |\, y) = \\
        & = \lambda(y)\,Q(x\, |\, y) \stepcounter{equation}\tag{\theequation}
\end{align*}

Отже, за Теоремою~\ref{theorem: detailed balance} розподіл~$\lambda(\theta)$ є стаціонарним для ланцюга Маркова, згенерованого згідно з алгоритмом МСМС.

\subsubsection*{Завдання (b)}
\addcontentsline{toc}{subsection}{Завдання (b)}

Нехай~$\lambda(\theta)$~--- апостеріорний розподіл вектора параметрів~$\theta=(\theta_1,\theta_2,\ldots,\theta_n)$. Вибірка Гіббса полягає у тому, щоб симулювати вибірку із заданого розподілу~$\lambda(\theta)$, генеруючи значення чергового параметра при фіксованих (ініціалізованих на першій ітерації) значеннях решти параметрів.

Завдання: показати, що вибірка Гіббса є частковим випадком алгоритму Метрополіса-Гастінгса.

\subsubsection*{Розв'язок}

Алгоритм Метрополіса-Гастінгса генерує ланцюг Маркова, крок за кроком приймаючи стан-пропозицію, згенеровану із деякого розподілу пропозицій, з певною імовірністю $\alpha$ (яка обчислюється з огляду на заданий апостеріорний розподіл). При цьому, фактично, апостеріорний роподіл може включати й інші параметри, які в рамках МСМС покладені фіксованим значенням. 

Вибірка Гіббса, своєю чергою, на кожному кроці завжди (тобто з імовірністю $\alpha=1$) приймає стан-пропозицію, згенеровану безпосередньо із апостеріорного розподілу. Іншими словами, вибірка Гіббса~--- частковий випадок алгоритму Метрополіса-Гастінгса з апостеріорним розподілом пропозицій та імовірністю прийняття пропозиції~$\alpha=1$. Формальний опис розв'язку наведено за \href{https://gregorygundersen.com/blog/2020/02/23/gibbs-sampling/}{\textit{посиланням}}.

\newpage
\subsection*{Задача 3. Empirical Bayes for exponential families}
\addcontentsline{toc}{section}{Задача 3. Empirical Bayes for exponential families}

\setcounter{subsection}{3}
\setcounter{equation}{0}

\subsubsection*{Постановка задачі}
\addcontentsline{toc}{subsection}{Постановка задачі}

Нехай задано випадковий вектор~$\vv{X}=(X_1,\ldots,X_n)$, який коротко позначимо як~$X$, з~$s$-параметризованої експоненціальної сім'ї розподілів з вектором параметрів~$\vv{\theta}=(\theta_1,\ldots,\theta_s)$, у короткому записі~$\theta$. Тоді щільність розподілу вектора~$X$ матиме вигляд:
\begin{equation}
    p_{\theta}(x) \equiv p(X=x \,|\, \theta) = e^{A(\theta)T(x) - B(\theta)}h(x)
\end{equation}

Згідно з умовою задачі функція~$A(\theta)=\theta$. Іншими словами, вектор~$X$ належить експоненціальній сім'ї розподілів у так званій канонічній формі:
\begin{equation}
    p_{\theta}(x) = e^{\theta T(x) - B(\theta)}h(x)
\end{equation}

Розписуючи скалярний добуток векторів~$\theta$ та~$T(x)$, матимемо такий еквівалентний запис:
\begin{equation}\label{eq: likelihood vec X | vec theta}
    p_{\theta}(x) = e^{\sum\limits_{j=1}^{s}\theta_j T_j(x) - B(\theta)}h(x)
\end{equation}

Крім того, в рамках задачі вектор~$\theta$ є випадковим вектором з деякого (апріорного) розподілу~$\lambda_{\gamma}(\theta)$, який своєю чергою параметризований фіксованим значенням параметра~$\gamma$.

Позначаючи апостеріорний розоділ вектора параметрів~$\theta$ як~$\lambda_{\gamma}(\theta \,|\, x)$, а безумовний розподіл випадкового вектора~$X$ як~$q_{\gamma}(x)$, у завданні слід показати, що для~$i=\overline{1,n}:$
\begin{equation}\label{eq: E sum}
    \mathbb{E}_{\gamma}\left[ \sum\limits_{j=1}^{s}\theta_j\frac{\partial T_j(x)}{\partial x_i} \,|\, X=x  \right] = \frac{\partial}{\partial x_i}\ln{q_{\gamma}(x)} - \frac{\partial}{\partial x_i}\ln{h(x)}
\end{equation}

А у випадку~$s=n$ та~$T(x)=x$, а також покладаючи значення параметра~$\gamma$ як оцінку максимальної правдоподібності
\begin{equation}\label{eq: gamma MLE}
    \widehat{\gamma} = \argmax\limits_{\gamma}L(X \,|\, \gamma) = \argmax\limits_{\gamma}q_{\gamma}(x),
\end{equation}
необхідно продемонструвати, що баєсова оцінка вектора~$\theta$ (тобто математичне сподівання апостеріорного розподілу) дорівнює, відповідно
\begin{equation}\label{eq: E posterior}
    \mathbb{E}_{\widehat{\gamma}}\left[ \theta \,|\, X=x \right] = \nabla_x \bigl( \ln{q_{\widehat{\gamma}}(x)} - \ln{h(x)} \bigr),
\end{equation}
де оператор набла визначений так:
\begin{equation}\label{eq: def nabla}
    \nabla_x = \left( \frac{\partial}{\partial x_1},\ldots,\frac{\partial}{\partial x_n} \right)
\end{equation}

\subsubsection*{Визначення математичного сподівання}
\addcontentsline{toc}{subsection}{Визначення математичного сподівання}

Розглянемо отримання математичного сподівання у виразі~\eqref{eq: E sum}. Наведемо задану баєсівську модель:
\begin{align}
    & (X_1,\ldots,X_n) \,|\, (\theta_1,\ldots,\theta_s) \sim p_{\theta}(x) \label{eq: vec X | vec theta} \\
    & (\theta_1,\ldots,\theta_s) \sim \lambda_{\gamma}(\theta) \label{eq: vec s theta}
\end{align} 

Запишемо згідно із формулою Баєса вираз для визначення апостеріорного розподілу $\lambda_{\gamma}(\theta \,|\, x)$ вектора~$\theta$ при заданому апріорному розподілі~$\lambda_{\gamma}(\theta)$, безумовному розподілі даних~$q_{\gamma}(x)$ та функції правдоподібності~$p_{\theta}(x)$~\eqref{eq: likelihood vec X | vec theta}:
\begin{equation}\label{eq: vec theta posterior}
    \lambda_{\gamma}(\theta \,|\, x) = \frac{p_{\theta}(x)\lambda_{\gamma}(\theta)}{q_{\gamma}(x)} = 
    \frac{h(x)}{q_{\gamma}(x)}\,\lambda_{\gamma}(\theta)\,e^{\sum\limits_{j=1}^{s}\theta_j T_j(x) - B(\theta)}
\end{equation}

Прологарифмуємо отриманий вираз:
\begin{equation}\label{eq: vec theta ln posterior}
    \ln{\lambda_{\gamma}(\theta \,|\, x)} = \ln{h(x)} - \ln{q_{\gamma}(x)} + \ln{\lambda_{\gamma}(\theta)} + \sum\limits_{j=1}^{s}\theta_j T_j(x) - B(\theta)
\end{equation}

Продиференціюємо~\eqref{eq: vec theta ln posterior} за координатою~$x_i$, враховуючи відсутню залежність від координати у функціях~$\lambda_{\gamma}(\theta)$ та~$B(\theta):$
\begin{equation}\label{eq: vec theta d/dx posterior}
    \frac{\partial}{\partial x_i}\ln{\lambda_{\gamma}(\theta \,|\, x)} = \frac{\partial}{\partial x_i}\ln{h(x)} - \frac{\partial}{\partial x_i}\ln{q_{\gamma}(x)} + \sum\limits_{j=1}^{s}\theta_j \frac{\partial T_j(x)}{\partial x_i}
\end{equation}

Таким чином, отримуємо співвідношення для шуканої суми:
\begin{equation}\label{eq: vec theta d/dx posterior reshaped}
    \sum\limits_{j=1}^{s}\theta_j \frac{\partial T_j(x)}{\partial x_i} = \frac{\partial}{\partial x_i}\ln{\lambda_{\gamma}(\theta \,|\, x)} + \frac{\partial}{\partial x_i}\ln{q_{\gamma}(x)} - \frac{\partial}{\partial x_i}\ln{h(x)}
\end{equation}

Обчислимо математичне сподівання виразу~\eqref{eq: vec theta d/dx posterior reshaped}, використовуючи властивість лінійності математичного сподівання та враховуючи відсутню залежність від вектора~$\theta$ у частини доданків: 
\begin{equation}\label{eq: vec theta d/dx expectation posterior}
    \mathbb{E}_{\gamma}\left[ \sum\limits_{j=1}^{s}\theta_j \frac{\partial T_j(x)}{\partial x_i} \,|\, X=x \right] = \mathbb{E}_{\gamma}\left[ \frac{\partial}{\partial x_i}\ln{\lambda_{\gamma}(\theta \,|\, x)} \,|\, X=x \right] + \frac{\partial}{\partial x_i}\ln{q_{\gamma}(x)} - \frac{\partial}{\partial x_i}\ln{h(x)}
\end{equation}

Детальніше розглянемо перший доданок у правій частині рівняння~\eqref{eq: vec theta d/dx expectation posterior}. За означенням умовного математичного сподівання для неперервної випадкової величини $g(\xi) \,|\, \eta:$
\begin{equation}\label{eq: def conditional expectation}
    \mathbb{E}\left[ g(\xi) \,|\, \eta \right] \overset{\scalebox{0.5}{def}}{=} \int\limits_{\mathbb{R}} g(y) \, f_{\xi \,|\, \eta}(y \,|\, \eta) \, dy
\end{equation}

Таким чином:
\begin{equation}\label{eq: vec theta d/dx ln expectation posterior}
    \mathbb{E}_{\gamma}\left[ \frac{\partial}{\partial x_i}\ln{\lambda_{\gamma}(\theta \,|\, x)} \,|\, X=x \right] = \int\limits_{\mathbb{R}^s} \frac{\partial}{\partial x_i}\ln{\lambda_{\gamma}(\theta \,|\, x)} \, \lambda_{\gamma}(\theta \,|\, x) \, d\theta
\end{equation}

У викладках нижче послідовно продиференціюємо функцію логарифма (1), скористаємося інтегральним правилом Лейбніца для винесення оператора диференціювання за межі знаку інтегрування (2) та використаємо властивість, що інтеграл довільної щільності розподілу на всій області визначення дорівнює одиниці (3): 
\begin{align*}\label{eq: Leibniz rule}
    \mathbb{E}_{\gamma}\left[ \frac{\partial}{\partial x_i}\ln{\lambda_{\gamma}(\theta \,|\, x)} \,|\, X=x \right] & = \int\limits_{\mathbb{R}^s} \frac{\partial}{\partial x_i}\ln{\lambda_{\gamma}(\theta \,|\, x)} \, \lambda_{\gamma}(\theta \,|\, x) \, d\theta = \\
    & \overset{\scalebox{0.5}{(1)}}{=} \int\limits_{\mathbb{R}^s} \frac{\frac{\partial}{\partial x_i}\lambda_{\gamma}(\theta \,|\, x)}{\lambda_{\gamma}(\theta \,|\, x)} \, \lambda_{\gamma}(\theta \,|\, x) \, d\theta = \\
    & = \int\limits_{\mathbb{R}^s} \frac{\partial}{\partial x_i}\lambda_{\gamma}(\theta \,|\, x) \, d\theta = \\
    & \overset{\scalebox{0.5}{(2)}}{=} \frac{\partial}{\partial x_i} \int\limits_{\mathbb{R}^s} \lambda_{\gamma}(\theta \,|\, x) \, d\theta = \\
    & \overset{\scalebox{0.5}{(3)}}{=} 0 \stepcounter{equation}\tag{\theequation}
\end{align*}

Отже, математичне сподівання~\eqref{eq: vec theta d/dx expectation posterior} отримає шуканий вигляд:
\begin{equation}\label{eq: vec theta d/dx final expectation posterior}
    \mathbb{E}_{\gamma}\left[ \sum\limits_{j=1}^{s}\theta_j \frac{\partial T_j(x)}{\partial x_i} \,|\, X=x \right] = \frac{\partial}{\partial x_i}\ln{q_{\gamma}(x)} - \frac{\partial}{\partial x_i}\ln{h(x)}
\end{equation}

\subsubsection*{Визначення баєсової оцінки вектора $\theta$}
\addcontentsline{toc}{subsection}{Визначення баєсової оцінки вектора $\theta$}

Нехай тепер задано баєсівську модель
\begin{align}
    & (X_1,\ldots,X_n) \,|\, (\theta_1,\ldots,\theta_s) \sim p_{\theta}(x) \label{eq: duplicated vec X | vec theta} \\
    & (\theta_1,\ldots,\theta_n) \sim \lambda_{\widehat{\gamma}}(\theta) \label{eq: vec n theta}
\end{align} 
над $n$-параметризованою експоненціальною сім'єю розподілів 
\begin{equation}\label{eq: n likelihood vec X | vec theta}
    p_{\theta}(x) = e^{\theta T(x) - B(\theta)}h(x)
\end{equation}
при фіксованому значенні параметра~$\widehat{\gamma}$ як оцінки максимальної правдоподібності~\eqref{eq: gamma MLE}. Крім того, у розподілі~\eqref{eq: n likelihood vec X | vec theta} покладено~$T(x)=x$, що буде використано у викладках нижче.

Процедура пошуку математичного сподівання~\eqref{eq: vec theta d/dx final expectation posterior} у попередньому підрозділі вказує шлях пошуку баєсової оцінки вектора~$\theta$. Тож першим кроком аналогічним чином запишемо згідно із формулою Баєса вираз для визначення апостеріорного розподілу $\lambda_{\widehat{\gamma}}(\theta \,|\, x)$ вектора~$\theta$ при заданому апріорному розподілі~$\lambda_{\widehat{\gamma}}(\theta)$, безумовному розподілі даних~$q_{\widehat{\gamma}}(x)$ та функції правдоподібності~$p_{\theta}(x)$~\eqref{eq: n likelihood vec X | vec theta}:
\begin{equation}\label{eq: n vec theta posterior}
    \lambda_{\widehat{\gamma}}(\theta \,|\, x) = \frac{p_{\theta}(x)\lambda_{\widehat{\gamma}}(\theta)}{q_{\widehat{\gamma}}(x)} = 
    \frac{h(x)}{q_{\widehat{\gamma}}(x)}\,\lambda_{\widehat{\gamma}}(\theta)\,e^{\theta T(x) - B(\theta)},
\end{equation}
де~$\theta \cdot T(x)$ є нічим іншим як скалярним добутком двох векторів. Прологарифмуємо отриманий вираз:
\begin{equation}\label{eq: n vec theta ln posterior}
    \ln{\lambda_{\widehat{\gamma}}(\theta \,|\, x)} = \ln{h(x)} - \ln{q_{\widehat{\gamma}}(x)} + \ln{\lambda_{\widehat{\gamma}}(\theta)} + \theta T(x) - B(\theta)
\end{equation}

Оскільки розмірність вектора~$\theta$ збігається із розмірністю вектора~$X$, застосуємо до~\eqref{eq: n vec theta ln posterior} оператор набла~$\nabla_x$~\eqref{eq: def nabla}:
\begin{equation}\label{eq: vec theta nabla posterior}
    \nabla_x\ln{\lambda_{\widehat{\gamma}}(\theta \,|\, x)} = \nabla_x\ln{h(x)} - \nabla_x\ln{q_{\widehat{\gamma}}(x)} +  \nabla_x\ln{\lambda_{\widehat{\gamma}}(\theta)} + \nabla_x\bigl( \theta T(x) \bigr),
\end{equation}
де на відміну від попереднього підрозділу у рівності~\eqref{eq: vec theta d/dx posterior} доданок з апріорним розподілом~$\nabla_x\ln{\lambda_{\widehat{\gamma}}(\theta)}$ не дорівнює нулю, адже значення гіперапараметра~$\widehat{\gamma}$ як оцінки максимальної правдоподідності~\eqref{eq: gamma MLE} містить функціональну залежність від даних~$x$.

Наступні кроки спрямуємо на визначення дії оператора набла на скалярний добуток двох векторів:
\begin{equation}
    \nabla_x\bigl( \theta T(x) \bigr) = \nabla_x(\theta) T(x) + \theta\,\nabla_x\bigl( T(x) \bigr) = \theta\,\nabla_x\bigl( T(x) \bigr),
\end{equation}
а оскільки в рамках завдання покладено~$T(x)=x$, то як наслідок
\begin{equation}
    \nabla_x\bigl( \theta T(x) \bigr) = \theta
\end{equation}

На додачу до властивості адитивності диференціального оператора набла, в результаті вираз~\eqref{eq: vec theta nabla posterior} отримує вид:
\begin{equation}
    \theta = \nabla_x\ln{\lambda_{\widehat{\gamma}}(\theta \,|\, x)} - \nabla_x\ln{\lambda_{\widehat{\gamma}}(\theta)} + \nabla_x\bigl( \ln{q_{\widehat{\gamma}}(x)} - \ln{h(x)} \bigr)
\end{equation}

Аналогічно до~\eqref{eq: vec theta d/dx expectation posterior} обчислимо умовне математичне сподівання: 
\begin{multline}\label{eq: theta Bayes estimation}
    \mathbb{E}_{\widehat{\gamma}} \left[ \theta \,|\, X=x \right] = \mathbb{E}_{\widehat{\gamma}} \left[ \nabla_x\ln{\lambda_{\widehat{\gamma}}(\theta \,|\, x)} \,|\, X=x \right] - \mathbb{E}_{\widehat{\gamma}} \left[ \nabla_x\ln{\lambda_{\widehat{\gamma}}(\theta)} \,|\, X=x \right] + \\
    + \nabla_x\bigl( \ln{q_{\widehat{\gamma}}(x)} - \ln{h(x)} \bigr)
\end{multline}

Згідно з означенням~\eqref{eq: def conditional expectation} та відповідно до викладок~\eqref{eq: Leibniz rule}:
\begin{align*}\label{eq: duplicated Leibniz rule}
    \mathbb{E}_{\widehat{\gamma}} \left[ \nabla_x\ln{\lambda_{\widehat{\gamma}}(\theta \,|\, x)} \,|\, X=x \right] & = \int\limits_{\mathbb{R}^n} \nabla_x\ln{\lambda_{\widehat{\gamma}}(\theta \,|\, x)} \, \lambda_{\widehat{\gamma}}(\theta \,|\, x) \, d\theta = \\
    & = \int\limits_{\mathbb{R}^n} \frac{\nabla_x\lambda_{\widehat{\gamma}}(\theta \,|\, x)}{\lambda_{\widehat{\gamma}}(\theta \,|\, x)} \, \lambda_{\widehat{\gamma}}(\theta \,|\, x) \, d\theta = \\
    & = \int\limits_{\mathbb{R}^n} \nabla_x\lambda_{\widehat{\gamma}}(\theta \,|\, x) \, d\theta = \\
    & = \nabla_x \int\limits_{\mathbb{R}^n} \lambda_{\widehat{\gamma}}(\theta \,|\, x) \, d\theta = \\
    & = 0 \stepcounter{equation}\tag{\theequation}
\end{align*}

Розпишемо другий доданок математичного сподівання~\eqref{eq: theta Bayes estimation}:
\begin{equation}
    \mathbb{E}_{\widehat{\gamma}} \left[ \nabla_x\ln{\lambda_{\widehat{\gamma}}(\theta)} \,|\, X=x \right] = \int\limits_{\mathbb{R}^n} \nabla_x\ln{\lambda_{\widehat{\gamma}}(\theta)} \, \lambda_{\widehat{\gamma}}(\theta \,|\, x) \, d\theta = \int\limits_{\mathbb{R}^n} \frac{\nabla_x\lambda_{\widehat{\gamma}}(\theta)}{\lambda_{\widehat{\gamma}}(\theta)} \, \lambda_{\widehat{\gamma}}(\theta \,|\, x) \, d\theta
\end{equation}

За правилом диференціювання складеної функції:
\begin{equation}\label{eq: chain rule}
    \nabla_x\lambda_{\widehat{\gamma}}(\theta) = \frac{\partial \lambda_{\widehat{\gamma}}(\theta)}{\partial x} = \frac{\partial \lambda_{\widehat{\gamma}}(\theta)}{\partial \gamma} \cdot \frac{\partial \gamma}{\partial x}
\end{equation}

Відтак, враховуючи інтегральне правило Лейбніца, матимемо такий еквівалентний запис:
\begin{equation}\label{eq: prior expectation}
    \mathbb{E}_{\widehat{\gamma}} \left[ \nabla_x\ln{\lambda_{\widehat{\gamma}}(\theta)} \,|\, X=x \right] = \frac{\partial \gamma}{\partial x} \int\limits_{\mathbb{R}^n} \frac{\partial \lambda_{\widehat{\gamma}}(\theta)}{\partial \gamma} \cdot \frac{\lambda_{\widehat{\gamma}}(\theta \,|\, x)}{\lambda_{\widehat{\gamma}}(\theta)} \, d\theta
\end{equation}

З іншого боку, гіперапарметр~$\widehat{\gamma}$ є оцінкою максимальної правдоподібності~\eqref{eq: gamma MLE} безумовного розподілу даних~$q_{\gamma}(x)$, а отже, похідна від функції~$q_{\widehat{\gamma}}(x)$ в точці~$\widehat{\gamma}$ дорівнює нулю:
\begin{equation}\label{eq: gamma zero MLE}
    \widehat{\gamma} = \argmax\limits_{\gamma}q_{\gamma}(x) \ \Longleftrightarrow \ \frac{\partial}{\partial \gamma} q_{\widehat{\gamma}}(x) = 0
\end{equation}

За формулою повної ймовірності~\eqref{eq: LTP} у застосуванні до повної групи подій, яка утворена вектором~$\theta$ з неперервних випадкових величин:
\begin{equation}
    q_{\widehat{\gamma}}(x) = \int\limits_{\mathbb{R}^n} p_{\theta}(x) \, \lambda_{\widehat{\gamma}}(\theta) \, d\theta
\end{equation}

Як наслідок, матимемо:
\begin{align*}\label{eq: q(x) derivative}
    \frac{\partial}{\partial \gamma}\, q_{\widehat{\gamma}}(x) & = \frac{\partial}{\partial \gamma} \int\limits_{\mathbb{R}^n} p_{\theta}(x) \, \lambda_{\widehat{\gamma}}(\theta) \, d\theta = \\
    & = \int\limits_{\mathbb{R}^n} \frac{\partial}{\partial \gamma} \Bigl( p_{\theta}(x) \cdot \lambda_{\widehat{\gamma}}(\theta) \Bigr) \, d\theta = \\
    & = \int\limits_{\mathbb{R}^n} \frac{\partial p_{\theta}(x)}{\partial \gamma}\,\lambda_{\widehat{\gamma}}(\theta) \, d\theta + \int\limits_{\mathbb{R}^n} p_{\theta}(x)\,\frac{\partial \lambda_{\widehat{\gamma}}(\theta)}{\partial \gamma} \, d\theta = \\
    & = \int\limits_{\mathbb{R}^n} p_{\theta}(x)\,\frac{\partial \lambda_{\widehat{\gamma}}(\theta)}{\partial \gamma} \, d\theta \stepcounter{equation}\tag{\theequation}
\end{align*}

Наостанок, за формулою Баєса~\eqref{eq: n vec theta posterior}:
\begin{equation}\label{eq: Bayes rule}
    \lambda_{\widehat{\gamma}}(\theta \,|\, x) = \frac{p_{\theta}(x)\lambda_{\widehat{\gamma}}(\theta)}{q_{\widehat{\gamma}}(x)} \ \Longleftrightarrow \ p_{\theta}(x) = \frac{\lambda_{\widehat{\gamma}}(\theta \,|\, x)}{\lambda_{\widehat{\gamma}}(\theta)}\,q_{\widehat{\gamma}}(x)
\end{equation}

Тоді в силу~\eqref{eq: gamma zero MLE} вираз~\eqref{eq: q(x) derivative} отримає вид:
\begin{equation}
    \frac{\partial}{\partial \gamma}\, q_{\widehat{\gamma}}(x) = 0 
    \ \Longleftrightarrow \ 
    q_{\widehat{\gamma}}(x) \int\limits_{\mathbb{R}^n} \frac{\lambda_{\widehat{\gamma}}(\theta \,|\, x)}{\lambda_{\widehat{\gamma}}(\theta)} \cdot \frac{\partial \lambda_{\widehat{\gamma}}(\theta)}{\partial \gamma} \, d\theta = 0
\end{equation}

Відповідно, шукане математичне сподівання~\eqref{eq: prior expectation} буде дорівнювати нулю:
\begin{equation}
    \mathbb{E}_{\widehat{\gamma}} \left[ \nabla_x\ln{\lambda_{\widehat{\gamma}}(\theta)} \,|\, X=x \right] = 0
\end{equation}

Отже, остаточний вигляд баєсової оцінки вектора~$\theta$~\eqref{eq: theta Bayes estimation} записуватиметься таким формульним співвідношенням: 
\begin{equation}
    \mathbb{E}_{\widehat{\gamma}} \left[ \theta \,|\, X=x \right] = \nabla_x\bigl( \ln{q_{\widehat{\gamma}}(x)} - \ln{h(x)} \bigr)
\end{equation}

\begin{remark}
    У підсумку можна зауважити, що на вигляд баєсової оцінки для експоненціальної сім'ї розподілів у канонічній формі впливають лише няавні дані та емпірична оцінка значення гіперпараметра апріорного розподілу (а не його безпосередній вигляд).
\end{remark}

\newpage
\subsection*{Задача 4. Gamma-Poisson empirical Bayes}
\addcontentsline{toc}{section}{Задача 4. Gamma-Poisson empirical Bayes}

\setcounter{subsection}{4}
\setcounter{equation}{0}

\subsubsection*{Постановка задачі}
\addcontentsline{toc}{subsection}{Постановка задачі}

Розглянемо модель такого вигляду:
\begin{align}
    & X_{ij} \,|\, \theta_i \overset{\scalebox{0.5}{ind}}{\sim} \mathrm{Poiss}(\theta_i),\ i=\overline{1,n},\ j=\overline{1,m}, \label{eq: X | theta} \\
    & \theta_i \overset{\scalebox{0.5}{i.i.d.}}{\sim} \mathrm{Gamma}(k,\widehat{\sigma}),\ i=\overline{1,n},  \label{eq: theta}
\end{align}
при цьому $k$ є відомим, а $\widehat{\sigma}$ визначене як оцінка максимальної правдоподібності. Завдання полягає у тому, щоб віднайти баєсову оцінку параметра~$\theta_i$, тобто математичне сподівання апостеріорного розподілу параметра~$\theta_i$. Також зазначимо, що відповідно до~\eqref{eq: X | theta} та~\eqref{eq: theta} дані організовані таким чином:
\begin{equation}
    \begin{gathered}
        \theta_1 : X_{11},X_{12},\ldots,X_{1m} \\
        \theta_2 : X_{21},X_{22},\ldots,X_{2m} \\
        \hfill \ldots \hfill  \\
        \theta_n : X_{n1},X_{n2},\ldots,X_{nm}
    \end{gathered} 
\end{equation}

Іншими словами, для кожної згенерованої випадкової величини~$\theta_i$ з Гамма-розподілу~\eqref{eq: theta} генерується набір випадкових величин~$X_{i1},X_{i2},\ldots,X_{im}$ з розподілу Пуасона з параметром~$\theta_i$.

\subsubsection*{Допоміжні теоретичні викладки}
\addcontentsline{toc}{subsection}{Допоміжні теоретичні викладки}

Перш за все, наведемо імовірнісні розподіли випадкових величин, про які ітиме мова. Нехай неперервна  випадкова величина~$\xi$ має Гамма-розподіл з параметрами~$\alpha>0$ та~$\beta>0:$
\begin{equation}
    \xi \sim Gamma(\alpha,\beta)
\end{equation}

На рівні позначень існує дві еквівалентні параметризації~$\alpha$ та~$\beta:$
\begin{itemize}
    \item <<shape parameter>>~$\alpha=k$ та <<scale parameter>>~$\beta=\sigma$;
    \item <<shape parameter>>~$\alpha=k$ та <<inverse scale parameter>>~$\beta=1/\sigma$, який ще називають <<rate parameter>>.
\end{itemize}

Відповідно до кожної з параметризацій щільність розподілу~$f_{\xi}(x)$ має відповідний вигляд. У випадку <<scale parameter>>~$\beta=\sigma:$ 
\begin{equation}\label{eq: dGamma scale parameter}
    \xi \sim \mathrm{Gamma}(k,\sigma) \ \Longleftrightarrow \ f_{\xi}(x) = \frac{x^{k-1}}{\sigma^{k}\Gamma(k)}\, e^{-x/\sigma}\, \mathbbm{1}(x>0), 
\end{equation}
де, відповідно, математичне сподівання та дисперсія складають
\begin{equation}\label{eq: dGamma scale parameter mean}
    \mathbb{E}\xi = k\sigma,\ \mathrm{Var}\xi=k\sigma^2
\end{equation}

У випадку ж <<rate parameter>>~$\beta=1/\sigma:$ 
\begin{equation}\label{eq: dGamma rate parameter}
    \xi \sim \mathrm{Gamma}(k,1/\sigma) \ \Longleftrightarrow \ f_{\xi}(x) = \frac{x^{k-1}}{\Gamma(k)}\,\sigma^{k} e^{-x\sigma}\, \mathbbm{1}(x>0), 
\end{equation}
де математичне сподівання та дисперсія
\begin{equation}\label{eq: dGamma rate parameter mean}
    \mathbb{E}\xi = \frac{1}{\sigma},\ \mathrm{Var}\xi=\frac{1}{\sigma^2}
\end{equation}

\begin{remark}
    Згідно з умовою завдання, у роботі розглядатиметься Гамма-розподіл саме зі <<scale parameter>>~$\beta=\sigma$. Спершу я не звернув уваги на цю приписку в умові завдання (адже раніше не зустрічав різну параметризацію у Гамма-розподілі), що спричинило деяку плутанину в процесі розписування викладок. Пізніше я відловив неточність і вирішив задля систематизації та ясності вказати означення, наведені вище.   
\end{remark}

Дискретна випадкова величина~$\eta$ має розподіл Пуасона з параметром~$\lambda$, якщо: 
\begin{equation}\label{eq: dPoisson}
    \eta \sim Poiss(\lambda) \ \Longleftrightarrow \ P(\eta=x) = \frac{\lambda^{x}e^{-\lambda}}{x!} 
\end{equation}

Кажуть, що дискретна випадкова величина~$\eta$ має від'ємний біноміальний розподіл з параметром кількості успіхів~$r$ та ймовірністю успіху~$p$, якщо: 
\begin{equation}\label{eq: dNB}
    \eta \sim NB(r,p) \ \Longleftrightarrow \ P(\eta=x) = \tbinom{x+r-1}{x}(1-p)^{x}p^{r}
\end{equation}

Наостанок, наведемо формулу повної ймовірності для деякої події~$A$ та повної групи подій~$\left\{ H_i : i = 1,2,3,\ldots \right\}$, визначеної та тому ж імовірнісному просторі, що і подія~$A:$
\begin{equation}\label{eq: LTP} % https://en.wikipedia.org/wiki/Law_of_total_probability
    P(A) = \sum\limits_{i}P(A \,|\, H_i) P(H_i)
\end{equation}  

Формула~\eqref{eq: LTP} застосовна і до пошуку ймовірності події~$A$ за умови деякої іншої події~$C:$
\begin{align*}\label{eq: conditional LTP} % https://en.wikipedia.org/wiki/Law_of_total_probability
    P(A \,|\, C) & = \frac{P(A,C)}{P(C)} = \\ 
    & = \frac{\sum\limits_{i}P(A,H_i,C)}{P(C)} = \\
    & = \frac{\sum\limits_{i}P(A \,|\, H_i,C) P(H_i \,|\, C) P(C)}{P(C)} = \\
    & = \sum\limits_{i}P(A \,|\, H_i,C) P(H_i \,|\, C) \stepcounter{equation}\tag{\theequation}
\end{align*}  

\subsubsection*{Визначення MLE для параметра~$\widehat{\sigma}$}
\addcontentsline{toc}{subsection}{Визначення MLE для параметра~$\widehat{\sigma}$}

Визначимо оцінку максимальної правдоподібності параметра~$\widehat{\sigma}$ у Гамма-розподілі~\eqref{eq: theta}:
\begin{equation}
    \widehat{\sigma} = \argmax\limits_{\sigma}{L(X_{11},X_{12},\ldots,X_{1m};\ldots;X_{n1},X_{n2},\ldots,X_{nm} \,|\, \sigma)}
\end{equation}

З огляду на незалежність наборів $X_{i1},X_{i2},\ldots,X_{im}$, функція правдоподібності матиме вид:
\begin{align}\label{eq: likelihood sigma}
    L(X_{11},X_{12},\ldots,X_{1m};\ldots;X_{n1},X_{n2},\ldots,X_{nm} \,|\, \sigma) &\overset{\scalebox{0.5}{ind}}{=} \prod\limits_{i=1}^{n} f(X_{i1},X_{i2},\ldots,X_{im} \,|\, \sigma) = \notag \\
    & \overset{\scalebox{0.5}{ind}}{=} \prod\limits_{i=1}^{n} \prod\limits_{j=1}^{m} f(X_{ij} \,|\, \sigma)
\end{align}

Використаємо формулу повної ймовірності~\eqref{eq: LTP} та формулу~\eqref{eq: conditional LTP} у застосуванні до повної групи подій, яка утворена неперервною випадковою величиною~$\theta_i$. Тоді розподіл~$f(X_{ij} \,|\, \sigma)$ у виразі~\eqref{eq: likelihood sigma} отримає вид:
\begin{equation}\label{eq: theta density}
    f(X_{ij} \,|\, \sigma) = \int\limits_{\mathbb{R}} f(X_{ij} \,|\, \theta_i,\sigma) f(\theta_i \,|\, \sigma)\, d\theta_i
\end{equation}

Враховуючи розподіл Пуасона для~$X_{ij}$~\eqref{eq: X | theta} та Гамма-розподілені величини~$\theta_i$~\eqref{eq: theta}, матимемо:
\begin{align*}\label{eq: edited theta density}
    f(X_{ij} \,|\, \sigma) & = \int\limits_{\mathbb{R}} f(X_{ij} \,|\, \theta_i,\sigma) f(\theta_i \,|\, \sigma)\, d\theta_i = \\
    & = \int\limits_{\mathbb{R}} \frac{\theta_i^{X_{ij}}e^{-\theta_i}}{X_{ij}!} \cdot \frac{\theta_{i}^{k-1}}{\sigma^{k}\Gamma(k)}\, e^{-\theta_i/\sigma}\, \mathbbm{1}(\theta_i>0)\, d\theta_i = \\
    & = C \, \sigma^{-k} \int\limits_{0}^{\infty} \theta_{i}^{X_{ij}+k-1}\, e^{-\theta_{i}\left( 1+\frac{1}{\sigma} \right)} \, d\theta_i \stepcounter{equation}\tag{\theequation}
\end{align*}

За означенням, Гамма-функція в деякій точці~$a$ при умові~$\mathrm{Re}(a)>0$ записується таким чином:
\begin{equation}\label{eq: G(a+1)}
    \Gamma(a) = \int\limits_{0}^{\infty}y^{a-1}\,e^{-y}\,dy
\end{equation}

Використаємо заміну~$y=bx$ й запишемо Гамма-функцію у точці~$a+1:$
\begin{equation}
    \Gamma(a+1) = \int\limits_{0}^{\infty}y^{a}\,e^{-y}\,dy = \int\limits_{0}^{\infty}(bx)^{a}\,e^{-bx}\,b\,dx = b^{a+1}\int\limits_{0}^{\infty}x^{a}\,e^{-bx}\,dx
\end{equation}

Як наслідок, матимемо:
\begin{equation}\label{eq: edited G(a+1)}
    \int\limits_{0}^{\infty}x^{a}\,e^{-bx}\,dx = b^{-a-1}\,\Gamma(a+1)
\end{equation}

Застосуємо~\eqref{eq: edited G(a+1)} до розподілу~\eqref{eq: edited theta density}, в результаті отримаємо:
\begin{align*}\label{eq: final theta density}
    f(X_{ij} \,|\, \sigma) & = C \, \sigma^{-k} \int\limits_{0}^{\infty} \theta_{i}^{X_{ij}+k-1}\, e^{-\theta_{i}\left( 1+\frac{1}{\sigma} \right)} \, d\theta_i = \\
    & = C \, \sigma^{-k}\, \left( 1+\frac{1}{\sigma}\right)^{-X_{ij}-k}\Gamma(X_{ij}+k) = \\
    & = C \, \sigma^{-k}\, \left( 1+\frac{1}{\sigma}\right)^{-X_{ij}-k} \stepcounter{equation}\tag{\theequation}
\end{align*}

Тоді функція правдоподібності~\eqref{eq: likelihood sigma} матиме такий остаточний вигляд:
\begin{equation}
    L = \prod\limits_{i=1}^{n} \prod\limits_{j=1}^{m} f(X_{ij} \,|\, \sigma) = \prod\limits_{i=1}^{n} \prod\limits_{j=1}^{m} C \, \sigma^{-k}\, \left( 1+\frac{1}{\sigma}\right)^{-X_{ij}-k} = C \, \sigma^{-nmk}\, \left( 1+\frac{1}{\sigma}\right)^{-nm\overline{X}-nmk},
\end{equation}
де позначено
\begin{equation}
    \overline{X} = \frac{1}{nm}\sum\limits_{i=1}^{n} \sum\limits_{j=1}^{m} X_{ij}
\end{equation}

Оскільки довільна диференційовна функція та логарифм від неї досягають екстремумів в однакових точках, то пошук розв'язку рівняння
\begin{equation}
    \frac{d}{d\sigma} \ln{L} = 0
\end{equation}
призведе до оцінки максимальної правдоподібності парамета~$\sigma:$
\begin{align}
    \frac{d}{d\sigma} \ln{L} & = \frac{d}{d\sigma} \left( \ln{C} - nmk\ln{\sigma} - (nm\overline{X}+nmk)\ln{\left( 1+\frac{1}{\sigma} \right)} \right) = \notag \\
    & = -\frac{nmk}{\sigma} + \frac{nm\overline{X}+nmk}{1+\frac{1}{\sigma}}\,\sigma^{-2} = \notag \\
    & = -\frac{nmk}{\sigma} + \frac{nm\overline{X}+nmk}{\sigma(\sigma+1)},
\end{align}
а відтак матимемо
\begin{equation}\label{eq: sigma MLE}
    \frac{d}{d\sigma} \ln{L} = 0 \ \Longleftrightarrow \ \widehat{\sigma} = \frac{\overline{X}}{k}
\end{equation}

\subsubsection*{Визначення баєсової оцінки параметра~$\theta_i$}
\addcontentsline{toc}{subsection}{Визначення баєсової оцінки параметра~$\theta_i$}

Відштовхуючись від~$h(\theta_i)$~--- апріорного Гамма-розподілу~\eqref{eq: theta} з параметрами~$k$ й~$\widehat{\sigma}$~--- та наявних даних $X_{i1},X_{i2},\ldots,X_{im}$~\eqref{eq: X | theta}, застосуємо формулу Баєса для пошуку апостеріорного розподілу параметра~$\theta_i:$
\begin{equation}
    h(\theta_i \,|\, X_{i1},X_{i2},\ldots,X_{im}) \propto h(\theta_i) L(X_{i1},X_{i2},\ldots,X_{im} \,|\, \theta_i)
\end{equation}

Отже, апріорний розподіл має вигляд:
\begin{equation}
    h(\theta_i) = \frac{\theta_{i}^{k-1}}{\widehat{\sigma}^{k}\Gamma(k)}\, e^{-\theta_{i}/\widehat{\sigma}}\, \mathbbm{1}(\theta_{i}>0)
\end{equation}

Функція правдоподібності, своєю чергою, розписуватиметься таким чином: 
\begin{equation}
    L(X_{i1},X_{i2},\ldots,X_{im} \,|\, \theta_i) \overset{\scalebox{0.5}{ind}}{=} \prod\limits_{j=1}^{m} P\left( X_{ij} \,|\, \theta_{i} \right) = \prod\limits_{j=1}^{m} \frac{\theta_{i}^{X_{ij}}e^{-\theta_{i}}}{X_{ij}!} = \frac{\theta_{i}^{\sum\limits_{j=1}^{m}X_{ij}}e^{-m\theta_{i}}}{X_{i1}!X_{i2}! \cdots X_{im}!}
\end{equation}

Отже, матимемо:
\begin{equation}
    L(X_{i1},X_{i2},\ldots,X_{im} \,|\, \theta_i) = C\, \theta_{i}^{m\overline{X}_i}\, e^{-m\theta_{i}}
\end{equation}

Відтак апостеріорний розподіл матиме вигляд:
\begin{align}
    h(\theta_i \,|\, X_{i1},X_{i2},\ldots,X_{im}) &\propto h(\theta_i) L(X_{i1},X_{i2},\ldots,X_{im} \,|\, \theta_i) = \notag \\
    & = \theta_{i}^{k-1}\, e^{-\theta_{i}/\widehat{\sigma}}\, \theta_{i}^{m\overline{X}_i}\, e^{-m\theta_{i}}\, \mathbbm{1}(\theta_{i}>0) = \notag \\
    & = \theta_{i}^{k+m\overline{X}_i-1}\, e^{-\theta_{i}(\widehat{\sigma}^{-1}+m)}\, \mathbbm{1}(\theta_{i}>0) \label{eq: theta posterior}
\end{align}

Окремо розпишемо множник експоненти:
\begin{equation}
    e^{-\theta_{i}(\widehat{\sigma}^{-1}+m)} = e^{-\theta_{i}\left( \frac{1}{\widehat{\sigma}}+m \right)} = e^{-\theta_{i}\left( \frac{1+\widehat{\sigma}m}{\widehat{\sigma}} \right)} = e^{-\theta_{i}/\left( \frac{\widehat{\sigma}}{1+\widehat{\sigma}m} \right)}
\end{equation}

Таким чином, впізнаємо у виразі~\eqref{eq: theta posterior} Гамма розподіл~\eqref{eq: dGamma scale parameter} із відповідними параметрами:
\begin{equation}
    \theta_i \,|\, X_{i1},X_{i2},\ldots,X_{im} \sim \mathrm{Gamma}\left( k+m\overline{X}_i,\frac{\widehat{\sigma}}{1+\widehat{\sigma}m} \right)
\end{equation}

А тоді відповідно до~\eqref{eq: dGamma scale parameter mean}, математичне сподівання апостеріорного розподілу (тобто баєсова оцінка параметра $\theta_{i}$) буде такою:
\begin{equation}
    \mathbb{E}(\theta_i \,|\, X_{i1},X_{i2},\ldots,X_{im}) = \left( k+m\overline{X}_i \right)\left( \frac{\widehat{\sigma}}{1+\widehat{\sigma}m} \right)
\end{equation}

Враховуючи оцінку максимальної правдоподібності~$\widehat{\sigma}=\overline{X}/k$~\eqref{eq: sigma MLE}, матимемо:
\begin{equation}\label{eq: my BE}
    \mathbb{E}(\theta_i \,|\, X_{i1},X_{i2},\ldots,X_{im}) = m\left( k/m+\overline{X}_i \right)\left( \frac{\overline{X}}{k+\overline{X}m} \right) = \left( k/m+\overline{X}_i \right)\left( \frac{\overline{X}}{k/m+\overline{X}} \right),
\end{equation}
де позначено
\begin{equation}
    \overline{X}_i = \frac{1}{m} \sum\limits_{j=1}^{m} X_{ij} \text{ та } \    \overline{X} = \frac{1}{nm}\sum\limits_{i=1}^{n} \sum\limits_{j=1}^{m} X_{ij}
\end{equation}

\begin{remark}
    Під час виведення MLE~\eqref{eq: sigma MLE} для параметра~$\sigma$, інтеграл у формулі~\eqref{eq: edited theta density} був обчислений без використання інформації про від'ємно біноміально розподілені дані. Насправді, я досі не до кінця усвідомив, яким чином слід було б використати цей факт у зв'язці із параметром~$\sigma$ без заданих параметрів розподілу~$r$ та~$p$. Можливо, я недогледів певне перетворення між розподілами.
\end{remark}

% \newpage
% \printbibliography[title={Перелік посилань}] % \nocite{*}
% \addcontentsline{toc}{section}{Перелік посилань}

\end{document}